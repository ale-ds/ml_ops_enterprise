# ğŸ—ï¸ MLOps Enterprise: California Housing Prediction

<p align="center">
  <img alt="Status" src="https://img.shields.io/badge/status-active-success.svg">
  <img alt="Python" src="https://img.shields.io/badge/python-3.11+-blue.svg">
  <img alt="MLflow" src="https://img.shields.io/badge/mlflow-2.x-orange.svg">
  <img alt="License" src="https://img.shields.io/badge/license-MIT-green.svg">
</p>

---

Este projeto demonstra a transformaÃ§Ã£o de um fluxo de trabalho de CiÃªncia de Dados, de um protÃ³tipo em Notebook para uma **arquitetura MLOps Enterprise robusta e modular**. O objetivo Ã© estabelecer um padrÃ£o que garanta reprodutibilidade, rastreabilidade e escalabilidade.

## ğŸ“‹ Ãndice

- [ğŸ“– Sobre o Projeto](#-sobre-o-projeto)
- [ğŸ“‚ Estrutura de Arquivos](#-estrutura-de-arquivos)
- [ğŸš€ Como Executar](#-como-executar)
  - [1. PrÃ©-requisitos](#1-prÃ©-requisitos)
  - [2. ConfiguraÃ§Ã£o do Ambiente](#2-configuraÃ§Ã£o-do-ambiente)
  - [3. InicializaÃ§Ã£o do Servidor MLflow](#3-inicializaÃ§Ã£o-do-servidor-mlflow)
  - [4. ExecuÃ§Ã£o do Pipeline de Treino](#4-execuÃ§Ã£o-do-pipeline-de-treino)
- [ğŸ§ª Executando os Testes](#ï¸-executando-os-testes)
- [ğŸ“Š Resultados e MÃ©tricas](#-resultados-e-mÃ©tricas)
- [ğŸ› ï¸ Guia de SoluÃ§Ã£o de Problemas](#ï¸-guia-de-soluÃ§Ã£o-de-problemas)
- [ğŸ“ LicenÃ§a](#-licenÃ§a)

---

## ğŸ“– Sobre o Projeto

O foco nÃ£o Ã© apenas treinar um modelo de previsÃ£o de preÃ§os de casas, mas estabelecer um padrÃ£o de **MLOps** que prioriza:

> **Reprodutibilidade:** Uso de `Makefiles` e ambientes virtuais para garantir que cada execuÃ§Ã£o seja consistente.

> **Rastreabilidade:** Tracking centralizado de experimentos com MLflow em uma arquitetura cliente-servidor.

> **Escalabilidade:** CÃ³digo modular (`src/`) totalmente desacoplado de configuraÃ§Ãµes (`config/`), permitindo fÃ¡cil manutenÃ§Ã£o e expansÃ£o.

## ğŸ“‚ Estrutura de Arquivos

A organizaÃ§Ã£o do projeto segue o princÃ­pio de *Separation of Concerns*, onde cada componente tem uma responsabilidade Ãºnica.

```
ml_ops_enterprise/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ main.yml        # Define o pipeline de CI/CD com GitHub Actions.
â”œâ”€â”€ .gitignore              # Arquivos e diretÃ³rios a serem ignorados pelo Git.
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ raw.yaml        # ConfiguraÃ§Ãµes para os dados brutos (ex: paths).
â”‚   â””â”€â”€ model/
â”‚       â””â”€â”€ random_forest.yaml # HiperparÃ¢metros e configuraÃ§Ãµes do modelo.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 01_raw/             # Armazena os dados brutos (nÃ£o versionados).
â”‚   â”œâ”€â”€ 02_processed/       # Armazena os dados processados.
â”‚   â””â”€â”€ 03_features/        # Armazena os dados apÃ³s a engenharia de features.
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ buid_project.sh     # Script para construir o projeto (ex: build de imagem Docker).
â”‚   â””â”€â”€ tree.conf           # ConfiguraÃ§Ã£o que contÃ©m a estrutura de diretÃ³rios e arquivos que serÃ£o criados.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py         # Torna o diretÃ³rio 'src' um pacote Python.
â”‚   â”œâ”€â”€ data_prep/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ extractor.py    # Scripts para extrair e carregar os dados.
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ transformer.py  # MÃ³dulos para engenharia e transformaÃ§Ã£o de features.
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ train.py        # LÃ³gica para treinamento e avaliaÃ§Ã£o do modelo.
â”‚   â”œâ”€â”€ serving/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ api.py          # CÃ³digo para servir o modelo como uma API (ex: com FastAPI).
â”‚   â””â”€â”€ validation/
â”‚       â””â”€â”€ schema.py       # Define o esquema de validaÃ§Ã£o dos dados de entrada.
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â””â”€â”€ test_model_integrity.py # Testes de integraÃ§Ã£o para validar a integridade do modelo.
â”‚   â””â”€â”€ unit/               # DiretÃ³rio para testes de unidade.
â”œâ”€â”€ conda.yaml              # DependÃªncias do projeto para ambientes Conda.
â”œâ”€â”€ Dockerfile              # Define a imagem Docker para a aplicaÃ§Ã£o.
â”œâ”€â”€ Makefile                # Orquestrador de comandos para automaÃ§Ã£o de tarefas (ex: `make train`).
â”œâ”€â”€ MLproject               # Define a estrutura e os entry points para o MLflow Projects.
â”œâ”€â”€ README.md               # DocumentaÃ§Ã£o do projeto.
â””â”€â”€ requirements.txt        # DependÃªncias do projeto para ambientes pip.
```

---

## ğŸš€ Como Executar

Siga os passos abaixo para configurar e executar o projeto.

### 1. PrÃ©-requisitos

- **Python 3.11+**
- **Make:** Geralmente nativo no Linux/macOS. Para Windows, utilize WSL ou Git Bash.

### 2. ConfiguraÃ§Ã£o do Ambiente

Crie um ambiente virtual para isolar as dependÃªncias do projeto.

```bash
# 1. Crie o ambiente virtual
python -m venv .venv

# 2. Ative o ambiente (ESSENCIAL!)
# No macOS/Linux:
source .venv/bin/activate
# No Windows:
# .venv\Scripts\activate

# 3. Instale as dependÃªncias
pip install -r requirements.txt
```

### 3. InicializaÃ§Ã£o do Servidor MLflow

Para simular um ambiente de produÃ§Ã£o, subimos o MLflow em modo servidor. **Abra um novo terminal**, ative o ambiente virtual (`source .venv/bin/activate`) e execute:

```bash
# A porta 5001 Ã© usada para evitar conflitos com o AirPlay no macOS
mlflow server \
    --backend-store-uri sqlite:///mlflow.db \
    --default-artifact-root ./mlruns \
    --host 127.0.0.1 \
    --port 5001
```

> Mantenha este terminal aberto. A interface do MLflow estarÃ¡ acessÃ­vel em **[http://127.0.0.1:5001](http://127.0.0.1:5001)**.

### 4. ExecuÃ§Ã£o do Pipeline de Treino

No seu terminal de desenvolvimento principal (com o `.venv` ativado), use um Ãºnico comando `make` para orquestrar todo o pipeline:

```bash
make train
```

Este comando irÃ¡:
1.  Definir a variÃ¡vel de ambiente `MLFLOW_TRACKING_URI` para se conectar ao servidor MLflow.
2.  Definir o nome do experimento no MLflow.
3.  Executar o pipeline de treinamento definido no `MLproject`.

---

## ğŸ§ª Executando os Testes

Este projeto inclui testes de integraÃ§Ã£o para garantir a integridade do modelo antes do deploy. O principal teste (`tests/integration/test_model_integrity.py`) simula um "Engenheiro de Deploy" que valida o contrato de entrada e saÃ­da do modelo mais recente registrado no MLflow.

Para executar os testes, utilize o seguinte comando:

```bash
make test
```

Este comando utiliza o `pytest` para descobrir e executar todos os testes localizados na pasta `tests/`. Ã‰ um passo crucial para garantir a qualidade e a confiabilidade do pipeline.

---

## ğŸ“Š Resultados e MÃ©tricas

Todos os experimentos sÃ£o rastreados e logados com:

- **ParÃ¢metros:** Capturados de `config/model/random_forest.yaml`.
- **MÃ©tricas:** `RMSE` do modelo.
- **Artefatos:** O modelo treinado, os arquivos de configuraÃ§Ã£o e grÃ¡ficos relevantes.

## ğŸ› ï¸ Guia de SoluÃ§Ã£o de Problemas

**ğŸ”´ Erro: `503 Service Unavailable` ou `403 Forbidden`**
- **Causa:** Conflito de porta no macOS. O serviÃ§o AirPlay Receiver pode usar a porta `5000`.
- **SoluÃ§Ã£o:** O projeto jÃ¡ estÃ¡ configurado para usar a porta `5001`. Garanta que o servidor MLflow foi iniciado nesta porta.

**ğŸ”´ Erro: `ModuleNotFoundError: No module named 'mlflow'`**
- **Causa:** O ambiente virtual nÃ£o foi ativado no terminal onde o comando `make train` foi executado.
- **SoluÃ§Ã£o:** Ative o ambiente com `source .venv/bin/activate` antes de executar o `make`.

**ğŸ”´ Erro: `RESOURCE_DOES_NOT_EXIST` (Run ID Mismatch)**
- **Causa:** Tentativa de definir um experimento (`mlflow.set_experiment`) dentro de um script que jÃ¡ foi iniciado por um `mlflow run`.
- **SoluÃ§Ã£o:** A arquitetura do projeto segue a regra: "O Orquestrador manda, o Script obedece". O `train.py` nÃ£o define URI ou experimento; ele apenas loga no contexto injetado pelo `Makefile`.

---

## ğŸ“ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais informaÃ§Ãµes.
